{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (classification_report, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare article bodies for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading article bodies for training...\n",
      "4566 articles loaded for training.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading article bodies for training...\")\n",
    "train_articles_dir = '../output'\n",
    "train_articles_df = pd.read_csv('input/train_v2.csv', index_col='article_id')\n",
    "train_article_ids = []\n",
    "train_article_bodies = []\n",
    "train_article_classes = []\n",
    "for article in os.listdir(train_articles_dir):\n",
    "    article_id = article.split('.')[0]\n",
    "    if article_id.isdigit():\n",
    "        with open(os.path.join(train_articles_dir, article), 'r') as f:\n",
    "            paragraphs = f.readlines()\n",
    "        f.close()\n",
    "        if paragraphs:\n",
    "            train_article_ids.append(article_id)\n",
    "            train_article_bodies.append(' '.join(paragraphs))\n",
    "            train_article_classes.append(train_articles_df.loc[int(article_id), 'category'])\n",
    "        \n",
    "print(\"%s articles loaded for training.\" %len(train_article_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_article_bodies = np.array(train_article_bodies)\n",
    "train_article_classes = np.array(train_article_classes)\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_article_bodies, train_article_classes, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TF-IDF matrix for articles.\n",
      "Accuracy on training set 0.8927\n",
      "Accuracy on validation set 0.6357\n",
      "Elapsed time: %s seconds... 60.4177\n"
     ]
    }
   ],
   "source": [
    "print(\"Constructing TF-IDF matrix for articles.\")\n",
    "start_time = time.time()\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=3500)\n",
    "tfidf_vect_ngram.fit(train_article_bodies)\n",
    "train_tfidf_ngram = tfidf_vect_ngram.transform(x_train)\n",
    "val_tfidf_ngram = tfidf_vect_ngram.transform(x_val)\n",
    "base_model = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140).fit(train_tfidf_ngram, y_train)\n",
    "predicts = base_model.predict(train_tfidf_ngram)\n",
    "print(\"Accuracy on training set %s\" %round(accuracy_score(y_train, predicts), 4))\n",
    "predicts = base_model.predict(val_tfidf_ngram)\n",
    "print(\"Accuracy on validation set %s\" %round(accuracy_score(y_val, predicts), 4))\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2893 articles loaded for training.\n"
     ]
    }
   ],
   "source": [
    "test_articles_dir = '../output_test'\n",
    "test_articles_df = pd.read_csv('input/test_v2.csv', index_col='article_id')\n",
    "test_article_ids = []\n",
    "test_article_bodies = []\n",
    "test_article_classes = []\n",
    "for article in os.listdir(test_articles_dir):\n",
    "    article_id = article.split('.')[0]\n",
    "    if article_id.isdigit():\n",
    "        with open(os.path.join(test_articles_dir, article), 'r') as f:\n",
    "            paragraphs = f.readlines()\n",
    "        f.close()\n",
    "        if paragraphs:\n",
    "            test_article_ids.append(article_id)\n",
    "            test_article_bodies.append(' '.join(paragraphs))\n",
    "        \n",
    "print(\"%s articles loaded for training.\" %len(test_article_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TF-IDF matrix for articles.\n",
      "Accuracy on training set 0.8412\n"
     ]
    }
   ],
   "source": [
    "train_article_bodies = np.array(train_article_bodies)\n",
    "train_article_classes = np.array(train_article_classes)\n",
    "\n",
    "print(\"Constructing TF-IDF matrix for articles.\")\n",
    "train_tfidf_ngram = tfidf_vect_ngram.transform(train_article_bodies)\n",
    "\n",
    "start_time = time.time()\n",
    "model = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140).fit(train_tfidf_ngram, train_article_classes)\n",
    "predicts = base_model.predict(train_tfidf_ngram)\n",
    "print(\"Accuracy on training set %s\" %round(accuracy_score(train_article_classes, predicts), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 0 ... 4 4 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 224,  115,  716,  155, 1683])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_ngram = tfidf_vect_ngram.transform(test_article_bodies)\n",
    "test_predicts = model.predict(test_tfidf_ngram)\n",
    "print(test_predicts)\n",
    "np.bincount(test_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.934608</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.008360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.164792</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.045876</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>0.892867</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.056761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>0.125468</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>0.494597</td>\n",
       "      <td>0.049553</td>\n",
       "      <td>0.313010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.075928</td>\n",
       "      <td>0.051367</td>\n",
       "      <td>0.139156</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>0.686499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4\n",
       "1768  0.013928  0.005259  0.934608  0.037846  0.008360\n",
       "3667  0.066890  0.164792  0.193029  0.045876  0.529412\n",
       "2339  0.892867  0.002526  0.040985  0.006861  0.056761\n",
       "2463  0.125468  0.017371  0.494597  0.049553  0.313010\n",
       "111   0.075928  0.051367  0.139156  0.047051  0.686499"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_predicts = model.predict_proba(test_tfidf_ngram)\n",
    "prob_predicts_df = pd.DataFrame(data=prob_predicts, index=test_article_ids)\n",
    "#prob_predicts_df.to_csv('../predictions/article_body_prediction.csv')\n",
    "prob_predicts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge training set with confident test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White House plays down speedy role for US natu...</td>\n",
       "      <td>http://www.thestar.com.my/News/World/2014/03/0...</td>\n",
       "      <td>The Star Online</td>\n",
       "      <td>www.thestar.com.my</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian Stocks Broadly Higher After Selloff</td>\n",
       "      <td>http://www.nasdaq.com/article/asian-stocks-bro...</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>www.nasdaq.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herbalife Ltd. (HLF) Probe Earns Bill Ackman B...</td>\n",
       "      <td>http://www.valuewalk.com/2014/03/herbalife-ltd...</td>\n",
       "      <td>ValueWalk</td>\n",
       "      <td>www.valuewalk.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOE to Get Fourth Deputy Governor as Carney Fi...</td>\n",
       "      <td>http://www.businessweek.com/news/2014-03-11/bo...</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>www.businessweek.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pilots get scrutiny</td>\n",
       "      <td>http://www.dispatch.com/content/stories/nation...</td>\n",
       "      <td>Columbus Dispatch</td>\n",
       "      <td>www.dispatch.com</td>\n",
       "      <td>1.400000e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "article_id                                                      \n",
       "1           White House plays down speedy role for US natu...   \n",
       "2                   Asian Stocks Broadly Higher After Selloff   \n",
       "3           Herbalife Ltd. (HLF) Probe Earns Bill Ackman B...   \n",
       "4           BOE to Get Fourth Deputy Governor as Carney Fi...   \n",
       "5                                         Pilots get scrutiny   \n",
       "\n",
       "                                                          url  \\\n",
       "article_id                                                      \n",
       "1           http://www.thestar.com.my/News/World/2014/03/0...   \n",
       "2           http://www.nasdaq.com/article/asian-stocks-bro...   \n",
       "3           http://www.valuewalk.com/2014/03/herbalife-ltd...   \n",
       "4           http://www.businessweek.com/news/2014-03-11/bo...   \n",
       "5           http://www.dispatch.com/content/stories/nation...   \n",
       "\n",
       "                    publisher              hostname     timestamp  \n",
       "article_id                                                         \n",
       "1             The Star Online    www.thestar.com.my  1.390000e+12  \n",
       "2                      NASDAQ        www.nasdaq.com  1.390000e+12  \n",
       "3                   ValueWalk     www.valuewalk.com  1.390000e+12  \n",
       "4                Businessweek  www.businessweek.com  1.390000e+12  \n",
       "5           Columbus Dispatch      www.dispatch.com  1.400000e+12  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_predicts = model.predict_proba(test_tfidf_ngram)\n",
    "prob_mask = np.amax(prob_predicts, axis=1) > 0.6\n",
    "selected_test_sample_ids = [article_id[0] for article_id in np.argwhere(prob_mask)]\n",
    "test_articles_df.head()\n",
    "# selected_test_articles = test_articles_df.loc[selected_test_sample_ids]\n",
    "# selected_test_articles['category'] = np.take(test_predicts, selected_test_sample_ids)\n",
    "# id_mapper = {}\n",
    "# for i in selected_test_articles.index:\n",
    "#     id_mapper[i] = 'x' + str(i)\n",
    "# selected_test_articles = selected_test_articles.rename(id_mapper)\n",
    "# selected_test_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2893, 5)\n",
      "(933, 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 1.0],\n",
       " [0.01, 0.0, 0.99],\n",
       " [0.02, 0.0, 0.98],\n",
       " [0.03, 0.0, 0.97],\n",
       " [0.04, 0.0, 0.96]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2538004 , 0.03950063, 0.21367529, 0.02257236, 0.47045133],\n",
       "       [0.07819359, 0.15902844, 0.2682253 , 0.06086434, 0.43368834],\n",
       "       [0.07713429, 0.04451456, 0.24779618, 0.06003981, 0.57051516],\n",
       "       ...,\n",
       "       [0.0265868 , 0.02076217, 0.08952271, 0.67264193, 0.19048634],\n",
       "       [0.02334936, 0.6398452 , 0.11418417, 0.03444034, 0.18818094],\n",
       "       [0.8091364 , 0.01016325, 0.07695226, 0.01566792, 0.08808017]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
