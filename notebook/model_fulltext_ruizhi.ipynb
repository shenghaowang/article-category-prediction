{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics,preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "\n",
    "from sklearn import metrics,preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, fbeta_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"input/train_v2.csv\")\n",
    "test_data = pd.read_csv(\"input/test_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Forex - Pound drops to one-month lows against ...</td>\n",
       "      <td>http://www.nasdaq.com/article/forex-pound-drop...</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>www.nasdaq.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hertz to Exit Equipment Rental Business in $2....</td>\n",
       "      <td>http://www.foxbusiness.com/industries/2014/03/...</td>\n",
       "      <td>Fox Business</td>\n",
       "      <td>www.foxbusiness.com</td>\n",
       "      <td>1.400000e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gold ETF inflows return</td>\n",
       "      <td>http://www.resourceinvestor.com/2014/03/09/gol...</td>\n",
       "      <td>Resource Investor</td>\n",
       "      <td>www.resourceinvestor.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hackers call Mt. Gox CEO a liar, say he still ...</td>\n",
       "      <td>http://bgr.com/2014/03/10/mt-gox-fraud-accusat...</td>\n",
       "      <td>BGR</td>\n",
       "      <td>bgr.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gold Climbs To Near 6-Month High On Concerns A...</td>\n",
       "      <td>http://www.forbes.com/sites/kitconews/2014/03/...</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>www.forbes.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0           1  Forex - Pound drops to one-month lows against ...   \n",
       "1           2  Hertz to Exit Equipment Rental Business in $2....   \n",
       "2           3                            Gold ETF inflows return   \n",
       "3           4  Hackers call Mt. Gox CEO a liar, say he still ...   \n",
       "4           5  Gold Climbs To Near 6-Month High On Concerns A...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  http://www.nasdaq.com/article/forex-pound-drop...             NASDAQ   \n",
       "1  http://www.foxbusiness.com/industries/2014/03/...       Fox Business   \n",
       "2  http://www.resourceinvestor.com/2014/03/09/gol...  Resource Investor   \n",
       "3  http://bgr.com/2014/03/10/mt-gox-fraud-accusat...                BGR   \n",
       "4  http://www.forbes.com/sites/kitconews/2014/03/...             Forbes   \n",
       "\n",
       "                   hostname     timestamp  category  \n",
       "0            www.nasdaq.com  1.390000e+12         4  \n",
       "1       www.foxbusiness.com  1.400000e+12         2  \n",
       "2  www.resourceinvestor.com  1.390000e+12         4  \n",
       "3                   bgr.com  1.390000e+12         4  \n",
       "4            www.forbes.com  1.390000e+12         4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_full.txt', 'w',errors='ignore') as myfile:\n",
    "#     for i in range(len(train_data['category'])):\n",
    "#         filename='raw_train/'+str(i+1)+'.txt'\n",
    "#         if os.path.exists(filename):\n",
    "#             with open(filename, 'r',errors='ignore') as data_file:\n",
    "#                 data=data_file.read().replace('\\n', '')\n",
    "#             myfile.write(train_data['title'][i]+\" \"+data+ '\\n')\n",
    "#         else:\n",
    "#             myfile.write(train_data['title'][i]+ '\\n')\n",
    "\n",
    "# #v2: remove numbers and punctuations\n",
    "# whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "# with open('train_full_clean.txt', 'w',errors='ignore') as myfile:\n",
    "#     for i in range(len(train_data['category'])):\n",
    "#         filename='raw_train/'+str(i+1)+'.txt'\n",
    "#         title=train_data['title'][i]\n",
    "#         title = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", title)\n",
    "#         title = ''.join(filter(whitelist.__contains__, title)).lower()\n",
    "#         title = ' '.join(title.split())\n",
    "#         if os.path.exists(filename):\n",
    "#             with open(filename, 'r',errors='ignore') as data_file:\n",
    "#                 data=data_file.read().replace('\\n', '')\n",
    "#                 data = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", data)\n",
    "#                 data = ''.join(filter(whitelist.__contains__, data)).lower()\n",
    "#                 data=' '.join(data.split())\n",
    "#             myfile.write(title+\" \"+data+ '\\n')\n",
    "#         else:\n",
    "#             myfile.write(title+ '\\n')\n",
    "\n",
    "# with open('test_full.txt', 'w',errors='ignore') as myfile:\n",
    "#     for i in range(len(test_data['title'])):\n",
    "#         filename='raw_test/'+str(i+1)+'.txt'\n",
    "#         if os.path.exists(filename):\n",
    "#             with open(filename, 'r',errors='ignore') as data_file:\n",
    "#                 data=data_file.read().replace('\\n', '')\n",
    "#             myfile.write(test_data['title'][i]+\" \"+data+ '\\n')\n",
    "#         else:\n",
    "#             myfile.write(test_data['title'][i]+ '\\n')\n",
    "\n",
    "# #v2 remove numbers and punctuations\n",
    "# whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "# with open('test_full_clean.txt', 'w',errors='ignore') as myfile:\n",
    "#     for i in range(len(test_data['title'])):\n",
    "#         filename='raw_test/'+str(i+1)+'.txt'\n",
    "#         title=test_data['title'][i]\n",
    "#         title = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", title)\n",
    "#         title = ''.join(filter(whitelist.__contains__, title)).lower()\n",
    "#         title = ' '.join(title.split())\n",
    "#         if os.path.exists(filename):\n",
    "#             with open(filename, 'r',errors='ignore') as data_file:\n",
    "#                 data=data_file.read().replace('\\n', '')\n",
    "#                 data = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", data)\n",
    "#                 data = ''.join(filter(whitelist.__contains__, data)).lower()\n",
    "#                 data=' '.join(data.split())\n",
    "#             myfile.write(title +\" \"+data+ '\\n')\n",
    "#         else:\n",
    "#             myfile.write(title + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forex - Pound drops to one-month lows against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hertz to Exit Equipment Rental Business in $2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold ETF inflows return Stock-market capital f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hackers call Mt. Gox CEO a liar, say he still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gold Climbs To Near 6-Month High On Concerns A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  Forex - Pound drops to one-month lows against ...\n",
       "1  Hertz to Exit Equipment Rental Business in $2....\n",
       "2  Gold ETF inflows return Stock-market capital f...\n",
       "3  Hackers call Mt. Gox CEO a liar, say he still ...\n",
       "4  Gold Climbs To Near 6-Month High On Concerns A..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainf='train_full_clean.txt'\n",
    "trainf='train_full.txt'\n",
    "#X = pd.read_csv(trainf,header=None,sep=\",\",names=['data'])\n",
    "with open(trainf) as f:\n",
    "    X = f.read().splitlines()\n",
    "\n",
    "df = pd.DataFrame({\"data\": X})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(article_id=train_data.article_id, category=train_data.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>article_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forex - Pound drops to one-month lows against ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  article_id  category\n",
       "0  Forex - Pound drops to one-month lows against ...           1         4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warn_filename_train = 'raw_train/warn.txt'\n",
    "error_filename_train = 'raw_train/error2.txt'\n",
    "warn_filename_test = 'raw_test/warn.txt'\n",
    "error_filename_test = 'raw_test/error2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_warn_or_error_list(filename):\n",
    "    with open(filename, errors='ignore') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    _list = []\n",
    "    for line in lines:\n",
    "        _list.append(line.split(',')[0])\n",
    "    return _list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_warn_list = read_warn_or_error_list(warn_filename_train)\n",
    "train_error_list = read_warn_or_error_list(error_filename_train)\n",
    "test_warn_list = read_warn_or_error_list(warn_filename_test)\n",
    "test_error_list = read_warn_or_error_list(error_filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noerror = df[~df.article_id.isin(train_warn_list)]\n",
    "# df_noerror = df[~df.article_id.isin(train_error_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5211, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noerror.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df_noerror[\"data\"], df_noerror[\"category\"], test_size = 0.2)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)  # indeed X_valid is a more accurate name\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)  # indeed Y_valid is a more accurate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label_train, feature_vector_valid, label_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label_train)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, label_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=3000)\n",
    "tfidf_vect_ngram.fit(df_noerror[\"data\"])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, N-Gram Vectors:  0.6826462128475551\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(LogisticRegression(penalty='l2', C=1.25, solver='lbfgs'), xtrain_tfidf_ngram, Y_train, xvalid_tfidf_ngram, Y_test)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, N-Gram Vectors:  0.6586768935762224\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(MultinomialNB(alpha=0.8), xtrain_tfidf_ngram, Y_train, xvalid_tfidf_ngram, Y_test)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, WordLevel TF-IDF:  0.6711409395973155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=160), xtrain_tfidf_ngram.tocsc(), Y_train, xvalid_tfidf_ngram.tocsc(), Y_test)\n",
    "print(\"Xgb, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, N-Gram Vectors:  0.653910149750416\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(RandomForestClassifier(n_estimators=200, criterion='entropy'), xtrain_tfidf_ngram, Y_train, xvalid_tfidf_ngram, Y_test)\n",
    "print(\"RF, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It seems that by filtering out those in the train_warn_list, the accuracy obtained is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission Using Different Mothods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White House plays down speedy role for US natu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  article_id\n",
       "0  White House plays down speedy role for US natu...           1"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainf='train_full_clean.txt'\n",
    "trainf='test_full.txt'\n",
    "#X = pd.read_csv(trainf,header=None,sep=\",\",names=['data'])\n",
    "with open(trainf) as f:\n",
    "    X = f.read().splitlines()\n",
    "\n",
    "df_test = pd.DataFrame({\"data\": X})\n",
    "df_test = df_test.assign(article_id=test_data.article_id)\n",
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter out those with warnings\n",
    "df_test = df_test[~df_test.article_id.isin(test_warn_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 2)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=3000)\n",
    "tfidf_vect_ngram.fit(df_noerror[\"data\"])\n",
    "\n",
    "train_tfidf_ngram =  tfidf_vect_ngram.transform(df_noerror[\"data\"])\n",
    "test_tfidf_ngram =  tfidf_vect_ngram.transform(df_test[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR on training set  0.7286509307234695\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(penalty='l2', C=1.25, solver='lbfgs')\n",
    "accuracy = train_model(classifier, train_tfidf_ngram, df_noerror[\"category\"], train_tfidf_ngram, df_noerror[\"category\"])\n",
    "print(\"LR on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier on Ngram Level TF IDF Vectors\n",
    "classifier =  MultinomialNB()\n",
    "accuracy = train_model(classifier, train_tfidf_ngram, df_noerror[\"category\"], train_tfidf_ngram, df_noerror[\"category\"])\n",
    "print(\"NB on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB on training set  0.8842832469775475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "classifier = xgboost.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140)\n",
    "accuracy = train_model(classifier, train_tfidf_ngram, df_noerror[\"category\"], train_tfidf_ngram, df_noerror[\"category\"])\n",
    "print(\"XGB on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF on training set  0.998272884283247\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=180, criterion='entropy')\n",
    "accuracy = train_model(classifier, train_tfidf_ngram, df_noerror[\"category\"], train_tfidf_ngram, df_noerror[\"category\"])\n",
    "print(\"RF on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data[\"category\"] = classifier.predict(test_tfidf_ngram.tocsc())\n",
    "df_test[\"category\"] = classifier.predict(test_tfidf_ngram)\n",
    "\n",
    "out = pd.DataFrame(df_test,columns=['article_id','category'])\n",
    "out.to_csv('prediction_fulltext.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update prediction by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv('prediction.csv')\n",
    "df_pred_fulltext = pd.read_csv('prediction_fulltext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_id = []\n",
    "updated_cat = []\n",
    "num_diff = 0\n",
    "for row in df_pred.itertuples():\n",
    "    updated_id.append(row.article_id)\n",
    "    cat_1 = row.category\n",
    "    _ls = df_pred_fulltext[df_pred_fulltext.article_id==row.article_id].category.values\n",
    "   \n",
    "    if _ls.size > 0:  # if calculated in fulltext prediction\n",
    "        cat_2 = _ls[0]\n",
    "        # print(cat_1, cat_2)\n",
    "        updated_cat.append(cat_2)\n",
    "        if cat_1 != cat_2:\n",
    "            num_diff += 1\n",
    "    else:\n",
    "        updated_cat.append(cat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = pd.DataFrame({\n",
    "    'article_id': updated_id,\n",
    "    'category': updated_cat\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated.to_csv('prediction_updated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
