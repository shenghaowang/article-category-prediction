{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "requirement:\n",
    "pip install goose3\n",
    "pip install pillow --upgrade\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goose3 import Goose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://driving.ca/mercedes-benz/auto-news/news/mercedes-benz-mulls-three-cylinder-hybrid-powertrains/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Goose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = g.extract(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mercedes-Benz mulls three-cylinder hybrid powertrains'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Smaller Mercedes models could see a three-cylinder hybrid powertrain in the near future'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.meta_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maller vehicles, such as the B-Class, CLA-Class and GLA-Class, but Hiel maintained we wonâ€™t see a larger Mercedes with a three-cylinder in the future.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.cleaned_text[-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article.cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = './raw_test'\n",
    "if not os.path.exists(raw_dir):\n",
    "    os.makedirs(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles_df = pd.read_csv(\"input/train_v2.csv\")\n",
    "articles_df = pd.read_csv(\"input/test_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>White House plays down speedy role for US natu...</td>\n",
       "      <td>http://www.thestar.com.my/News/World/2014/03/0...</td>\n",
       "      <td>The Star Online</td>\n",
       "      <td>www.thestar.com.my</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Asian Stocks Broadly Higher After Selloff</td>\n",
       "      <td>http://www.nasdaq.com/article/asian-stocks-bro...</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>www.nasdaq.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Herbalife Ltd. (HLF) Probe Earns Bill Ackman B...</td>\n",
       "      <td>http://www.valuewalk.com/2014/03/herbalife-ltd...</td>\n",
       "      <td>ValueWalk</td>\n",
       "      <td>www.valuewalk.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BOE to Get Fourth Deputy Governor as Carney Fi...</td>\n",
       "      <td>http://www.businessweek.com/news/2014-03-11/bo...</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>www.businessweek.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pilots get scrutiny</td>\n",
       "      <td>http://www.dispatch.com/content/stories/nation...</td>\n",
       "      <td>Columbus Dispatch</td>\n",
       "      <td>www.dispatch.com</td>\n",
       "      <td>1.400000e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0           1  White House plays down speedy role for US natu...   \n",
       "1           2          Asian Stocks Broadly Higher After Selloff   \n",
       "2           3  Herbalife Ltd. (HLF) Probe Earns Bill Ackman B...   \n",
       "3           4  BOE to Get Fourth Deputy Governor as Carney Fi...   \n",
       "4           5                                Pilots get scrutiny   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  http://www.thestar.com.my/News/World/2014/03/0...    The Star Online   \n",
       "1  http://www.nasdaq.com/article/asian-stocks-bro...             NASDAQ   \n",
       "2  http://www.valuewalk.com/2014/03/herbalife-ltd...          ValueWalk   \n",
       "3  http://www.businessweek.com/news/2014-03-11/bo...       Businessweek   \n",
       "4  http://www.dispatch.com/content/stories/nation...  Columbus Dispatch   \n",
       "\n",
       "               hostname     timestamp  \n",
       "0    www.thestar.com.my  1.390000e+12  \n",
       "1        www.nasdaq.com  1.390000e+12  \n",
       "2     www.valuewalk.com  1.390000e+12  \n",
       "3  www.businessweek.com  1.390000e+12  \n",
       "4      www.dispatch.com  1.400000e+12  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3826"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_df['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  10168.9897\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(len(articles_df['url'])):\n",
    "    url=articles_df['url'][i]\n",
    "    try:\n",
    "        article = g.extract(url=url)\n",
    "    except:\n",
    "        f = open(raw_dir+'/error.txt','a',errors='ignore')\n",
    "        f.write(str(i+1)+ \",url_error\\n\")\n",
    "        f.close()\n",
    "        continue\n",
    "    #print(article.title)\n",
    "    #print(articles_df['title'][i])\n",
    "    #print(article.title==articles_df['title'][i])\n",
    "    #print(article.cleaned_text)\n",
    "    if similar(article.title,articles_df['title'][i])<0.5:# and len(article.cleaned_text)<1000:\n",
    "        #print(\"not found:\")\n",
    "        #print(article.title)\n",
    "        #print(articles_df['title'][i])\n",
    "        #print(article.cleaned_text)\n",
    "        #print(len(article.cleaned_text))\n",
    "        f = open(raw_dir+'/error.txt','a',errors='ignore')\n",
    "        f.write(str(i+1)+ \",not_found\\n\")\n",
    "        f.close()\n",
    "        continue\n",
    "    #print(\"correct:\")\n",
    "    #print(len(article.cleaned_text))\n",
    "    f = open(raw_dir+'/'+str(i+1) + '.txt','w',errors='ignore')\n",
    "    f.write(article.cleaned_text)\n",
    "    f.close()\n",
    "print(\"Elapsed time: \",round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recover dead urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "#ip=raw_input(\"What would you like to search for? \")\n",
    "\n",
    "#for url in search(\"What would you like to search for? \", stop=1):\n",
    "#     print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = './raw_train'\n",
    "if not os.path.exists(raw_dir):\n",
    "    os.makedirs(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv(\"input/train_v2.csv\")\n",
    "#articles_df = pd.read_csv(\"input/test_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Forex - Pound drops to one-month lows against ...</td>\n",
       "      <td>http://www.nasdaq.com/article/forex-pound-drop...</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>www.nasdaq.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hertz to Exit Equipment Rental Business in $2....</td>\n",
       "      <td>http://www.foxbusiness.com/industries/2014/03/...</td>\n",
       "      <td>Fox Business</td>\n",
       "      <td>www.foxbusiness.com</td>\n",
       "      <td>1.400000e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gold ETF inflows return</td>\n",
       "      <td>http://www.resourceinvestor.com/2014/03/09/gol...</td>\n",
       "      <td>Resource Investor</td>\n",
       "      <td>www.resourceinvestor.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hackers call Mt. Gox CEO a liar, say he still ...</td>\n",
       "      <td>http://bgr.com/2014/03/10/mt-gox-fraud-accusat...</td>\n",
       "      <td>BGR</td>\n",
       "      <td>bgr.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gold Climbs To Near 6-Month High On Concerns A...</td>\n",
       "      <td>http://www.forbes.com/sites/kitconews/2014/03/...</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>www.forbes.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0           1  Forex - Pound drops to one-month lows against ...   \n",
       "1           2  Hertz to Exit Equipment Rental Business in $2....   \n",
       "2           3                            Gold ETF inflows return   \n",
       "3           4  Hackers call Mt. Gox CEO a liar, say he still ...   \n",
       "4           5  Gold Climbs To Near 6-Month High On Concerns A...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  http://www.nasdaq.com/article/forex-pound-drop...             NASDAQ   \n",
       "1  http://www.foxbusiness.com/industries/2014/03/...       Fox Business   \n",
       "2  http://www.resourceinvestor.com/2014/03/09/gol...  Resource Investor   \n",
       "3  http://bgr.com/2014/03/10/mt-gox-fraud-accusat...                BGR   \n",
       "4  http://www.forbes.com/sites/kitconews/2014/03/...             Forbes   \n",
       "\n",
       "                   hostname     timestamp  category  \n",
       "0            www.nasdaq.com  1.390000e+12         4  \n",
       "1       www.foxbusiness.com  1.400000e+12         2  \n",
       "2  www.resourceinvestor.com  1.390000e+12         4  \n",
       "3                   bgr.com  1.390000e+12         4  \n",
       "4            www.forbes.com  1.390000e+12         4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data = pd.read_csv('raw_train/error.txt', sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1\n",
       "0  2  not_found\n",
       "1  3  not_found\n",
       "2  4  not_found\n",
       "3  6  not_found\n",
       "4  9  not_found"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def saveArticle(url,article_id,dest):\n",
    "    try:\n",
    "        article = g.extract(url=url)\n",
    "    except:\n",
    "        f = open(dest+'/error.txt','a',errors='ignore')\n",
    "        f.write(str(article_id)+ \",url_error\\n\")\n",
    "        f.close()\n",
    "        return\n",
    "    #print(article.title)\n",
    "    #print(articles_df['title'][i])\n",
    "    #print(article.title==articles_df['title'][i])\n",
    "    #print(article.cleaned_text)\n",
    "    if similar(article.title,articles_df['title'][i])<0.5:# and len(article.cleaned_text)<1000:\n",
    "        #print(\"not found:\")\n",
    "        #print(article.title)\n",
    "        #print(articles_df['title'][i])\n",
    "        #print(article.cleaned_text)\n",
    "        #print(len(article.cleaned_text))\n",
    "        f = open(raw_dir+'/error.txt','a',errors='ignore')\n",
    "        f.write(str(i+1)+ \",not_found\\n\")\n",
    "        f.close()\n",
    "        return\n",
    "    #print(\"correct:\")\n",
    "    #print(len(article.cleaned_text))\n",
    "    f = open(dest+'/'+str(article_id) + '.txt','w',errors='ignore')\n",
    "    f.write(article.cleaned_text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2725, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_data[0][166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in error_data[0]:\n",
    "#for i in range(3):\n",
    "    title=articles_df['title'][i-1]\n",
    "    try:\n",
    "        url=next(search(title, stop=1))\n",
    "        article = g.extract(url=url)\n",
    "    except:\n",
    "        f = open(raw_dir+'/error2.txt','a',errors='ignore')\n",
    "        f.write(str(i)+ \",url_error\\n\")\n",
    "        f.close()\n",
    "        continue\n",
    "    #print(article.title)\n",
    "    #print(articles_df['title'][i])\n",
    "    #print(article.title==articles_df['title'][i])\n",
    "    #print(article.cleaned_text)\n",
    "    if similar(article.title,title)<0.5:# and len(article.cleaned_text)<1000:\n",
    "        #print(\"not found:\")\n",
    "        #print(article.title)\n",
    "        #print(articles_df['title'][i])\n",
    "        #print(article.cleaned_text)\n",
    "        #print(len(article.cleaned_text))\n",
    "        f = open(raw_dir+'/warn.txt','a',errors='ignore')\n",
    "        f.write(str(i)+ \",no_original,\"+title+\",\"+article.title+\"\\n\")\n",
    "        f.close()\n",
    "    #print(\"correct:\")\n",
    "    #print(len(article.cleaned_text))\n",
    "    #if os.path.exists(raw_dir+'/'+str(i) + '.txt'):\n",
    "    #    print(i)\n",
    "    #    continue\n",
    "    f = open(raw_dir+'/'+str(i) + '.txt','w',errors='ignore')\n",
    "    f.write(article.cleaned_text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2203\n",
      "HTTP Error 503: Service Unavailable\n",
      "HTTP Error 503: Service Unavailable\n",
      "HTTP Error 503: Service Unavailable\n",
      "HTTP Error 503: Service Unavailable\n",
      "HTTP Error 503: Service Unavailable\n",
      "HTTP Error 503: Service Unavailable\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_urls=5\n",
    "max_trial=5\n",
    "for i in error_data[0]:\n",
    "#for i in range(3):\n",
    "    if i%100<6:\n",
    "        print(i)\n",
    "    title=articles_df['title'][i-1]\n",
    "    urls=[]\n",
    "    search_successful=False\n",
    "    #try query google max trial times if one query got problem\n",
    "    for j in range(max_trial):\n",
    "        try:\n",
    "            searchResult=search(title, stop=2)\n",
    "            \n",
    "            for k in range(max_urls):\n",
    "                urls.append(next(searchResult))\n",
    "            search_successful=True\n",
    "            break\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    if not search_successful:\n",
    "        f = open(raw_dir+'/error2.txt','a',errors='ignore')\n",
    "        f.write(str(i)+ \",search_error\\n\")\n",
    "        f.close()\n",
    "        continue\n",
    "    #print(urls)\n",
    "    articles=[]\n",
    "    for j in range(max_urls):\n",
    "        for k in range(max_trial):\n",
    "            try:\n",
    "                article = g.extract(urls[j])\n",
    "                article_successful=True\n",
    "                articles.append(article)\n",
    "                break\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "    if len(articles)==0:\n",
    "        f = open(raw_dir+'/error2.txt','a',errors='ignore')\n",
    "        f.write(str(i)+ \",url_error\\n\")\n",
    "        f.close()\n",
    "        continue\n",
    "    best_article=0\n",
    "    max_similarity=0\n",
    "    for j in range(len(articles)):\n",
    "        #print(articles[j].title)\n",
    "        similarity=similar(articles[j].title,title)\n",
    "        if similarity>max_similarity:\n",
    "            best_article=j\n",
    "            max_similarity=similarity\n",
    "    #print(best_article)\n",
    "    #print(max_similarity)\n",
    "    #print(article.title)\n",
    "    #print(articles_df['title'][i])\n",
    "    #print(article.title==articles_df['title'][i])\n",
    "    #print(article.cleaned_text)\n",
    "    if max_similarity<0.5:# and len(article.cleaned_text)<1000:\n",
    "        #print(\"not found:\")\n",
    "        #print(article.title)\n",
    "        #print(articles_df['title'][i])\n",
    "        #print(article.cleaned_text)\n",
    "        #print(len(article.cleaned_text))\n",
    "        f = open(raw_dir+'/warn.txt','a',errors='ignore')\n",
    "        f.write(str(i)+ \",original_not_found,\"+title+\",\"+article.title+\"\\n\")\n",
    "        f.close()\n",
    "    #print(\"correct:\")\n",
    "    #print(len(article.cleaned_text))\n",
    "    #if os.path.exists(raw_dir+'/'+str(i) + '.txt'):\n",
    "    #    print(i)\n",
    "    #    continue\n",
    "    f = open(raw_dir+'/'+str(i) + '.txt','w',errors='ignore')\n",
    "    f.write(articles[best_article].cleaned_text)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
