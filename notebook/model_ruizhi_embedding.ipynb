{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "\n",
    "from sklearn import metrics,preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, fbeta_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/train_v2.csv\")\n",
    "test_data = pd.read_csv(\"../input/test_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Forex - Pound drops to one-month lows against ...</td>\n",
       "      <td>http://www.nasdaq.com/article/forex-pound-drop...</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>www.nasdaq.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0           1  Forex - Pound drops to one-month lows against ...   \n",
       "\n",
       "                                                 url publisher  \\\n",
       "0  http://www.nasdaq.com/article/forex-pound-drop...    NASDAQ   \n",
       "\n",
       "         hostname     timestamp  category  \n",
       "0  www.nasdaq.com  1.390000e+12         4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11871c550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADudJREFUeJzt3X+s3XV9x/HnS1DCphgMd01tq8WsTgtudTSVxWXBmY1O\nlxWTzZQ/bLM46kJ1mJhl4P6Qf5rwx9SMRNjqZJTF2XT+CM0GGqxuxiwIF9ZY2trRCYzelHKdy6rR\n4Fre++N+up5cWu7PnlP4PB/Jyfmc9/fHeZ9voK/z/XVuqgpJUp9eMeoGJEmjYwhIUscMAUnqmCEg\nSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOnbhqBuYyWWXXVYrV64cdRuS9JLyyCOP/KCqxmaa77wP\ngZUrVzI+Pj7qNiTpJSXJU7OZz8NBktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI6d\n9zeLLdTKm/9p1C0A8ORt7x11C5L0Au4JSFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNA\nkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdWzGEEiyIsk3kxxIsj/JTa1+a5KJJHvb4z0Dy9yS5HCS\nQ0muHahflWRfm3Z7kpybjyVJmo3Z/JT0CeBjVfVoktcAjyR5oE37dFX9xeDMSVYDG4ErgNcDX0/y\n5qo6CdwJ3AB8B7gPWA/cvzgfRZI0VzPuCVTV0ap6tI1/BBwElr3IIhuAnVX1XFU9ARwG1iVZClxS\nVQ9WVQH3ANct+BNIkuZtTucEkqwE3s7UN3mAjyT5bpK7klzaasuApwcWO9Jqy9p4el2SNCKzDoEk\nrwa+BHy0qo4zdWjnTcAa4CjwycVqKsmWJONJxicnJxdrtZKkaWYVAkleyVQAfL6qvgxQVceq6mRV\nPQ98FljXZp8AVgwsvrzVJtp4ev0Fqmp7Va2tqrVjY2Nz+TySpDmYzdVBAT4HHKyqTw3Ulw7M9j7g\nsTbeDWxMclGSy4FVwENVdRQ4nuTqts5NwL2L9DkkSfMwm6uD3gl8ANiXZG+rfRy4PskaoIAngQ8B\nVNX+JLuAA0xdWbS1XRkEcCNwN3AxU1cFeWWQJI3QjCFQVd8GznQ9/30vssw2YNsZ6uPAlXNpUJJ0\n7njHsCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6\nZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOG\ngCR1zBCQpI4ZApLUMUNAkjpmCEhSx2YMgSQrknwzyYEk+5Pc1OqvS/JAksfb86UDy9yS5HCSQ0mu\nHahflWRfm3Z7kpybjyVJmo3Z7AmcAD5WVauBq4GtSVYDNwN7qmoVsKe9pk3bCFwBrAfuSHJBW9ed\nwA3AqvZYv4ifRZI0RzOGQFUdrapH2/hHwEFgGbAB2NFm2wFc18YbgJ1V9VxVPQEcBtYlWQpcUlUP\nVlUB9wwsI0kagTmdE0iyEng78B1gSVUdbZOeAZa08TLg6YHFjrTasjaeXj/T+2xJMp5kfHJyci4t\nSpLmYNYhkOTVwJeAj1bV8cFp7Zt9LVZTVbW9qtZW1dqxsbHFWq0kaZpZhUCSVzIVAJ+vqi+38rF2\niIf2/GyrTwArBhZf3moTbTy9LkkakdlcHRTgc8DBqvrUwKTdwOY23gzcO1DfmOSiJJczdQL4oXbo\n6HiSq9s6Nw0sI0kagQtnMc87gQ8A+5LsbbWPA7cBu5J8EHgKeD9AVe1Psgs4wNSVRVur6mRb7kbg\nbuBi4P72kCSNyIwhUFXfBs52Pf+7z7LMNmDbGerjwJVzaVCSdO54x7AkdcwQkKSOGQKS1DFDQJI6\nZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOG\ngCR1bDZ/XlIvF7e+dtQdTLn1f0bdgaTGPQFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpm\nCEhSxwwBSeqYISBJHTMEJKljM4ZAkruSPJvksYHarUkmkuxtj/cMTLslyeEkh5JcO1C/Ksm+Nu32\nJFn8jyNJmovZ7AncDaw/Q/3TVbWmPe4DSLIa2Ahc0Za5I8kFbf47gRuAVe1xpnVKkoZoxhCoqm8B\nP5zl+jYAO6vquap6AjgMrEuyFLikqh6sqgLuAa6bb9OSpMWxkHMCH0ny3Xa46NJWWwY8PTDPkVZb\n1sbT62eUZEuS8STjk5OTC2hRkvRi5hsCdwJvAtYAR4FPLlpHQFVtr6q1VbV2bGxsMVctSRowrxCo\nqmNVdbKqngc+C6xrkyaAFQOzLm+1iTaeXpckjdC8QqAd4z/lfcCpK4d2AxuTXJTkcqZOAD9UVUeB\n40mublcFbQLuXUDfkqRFMOOfl0zyBeAa4LIkR4BPANckWQMU8CTwIYCq2p9kF3AAOAFsraqTbVU3\nMnWl0cXA/e0hSRqhGUOgqq4/Q/lzLzL/NmDbGerjwJVz6k6SdE55x7AkdcwQkKSOGQKS1DFDQJI6\nZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOG\ngCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghI\nUsdmDIEkdyV5NsljA7XXJXkgyePt+dKBabckOZzkUJJrB+pXJdnXpt2eJIv/cSRJczGbPYG7gfXT\najcDe6pqFbCnvSbJamAjcEVb5o4kF7Rl7gRuAFa1x/R1SpKGbMYQqKpvAT+cVt4A7GjjHcB1A/Wd\nVfVcVT0BHAbWJVkKXFJVD1ZVAfcMLCNJGpH5nhNYUlVH2/gZYEkbLwOeHpjvSKsta+Pp9TNKsiXJ\neJLxycnJebYoSZrJgk8Mt2/2tQi9DK5ze1Wtraq1Y2Nji7lqSdKA+YbAsXaIh/b8bKtPACsG5lve\nahNtPL0uSRqh+YbAbmBzG28G7h2ob0xyUZLLmToB/FA7dHQ8ydXtqqBNA8tIkkbkwplmSPIF4Brg\nsiRHgE8AtwG7knwQeAp4P0BV7U+yCzgAnAC2VtXJtqobmbrS6GLg/vaQJI3QjCFQVdefZdK7zzL/\nNmDbGerjwJVz6k6SdE55x7AkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXM\nEJCkjs34sxHSy9Hbdrxt1C0AsG/zvlG3oM65JyBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghI\nUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWMLCoEk\nTybZl2RvkvFWe12SB5I83p4vHZj/liSHkxxKcu1Cm5ckLcxi7Am8q6rWVNXa9vpmYE9VrQL2tNck\nWQ1sBK4A1gN3JLlgEd5fkjRP5+Jw0AZgRxvvAK4bqO+squeq6gngMLDuHLy/JGmWFhoCBXw9ySNJ\ntrTakqo62sbPAEvaeBnw9MCyR1rtBZJsSTKeZHxycnKBLUqSzubCBS7/61U1keQXgAeSfG9wYlVV\nkprrSqtqO7AdYO3atXNeXpI0OwvaE6iqifb8LPAVpg7vHEuyFKA9P9tmnwBWDCy+vNUkSSMy7xBI\n8vNJXnNqDPw28BiwG9jcZtsM3NvGu4GNSS5KcjmwCnhovu8vSVq4hRwOWgJ8Jcmp9fx9VX01ycPA\nriQfBJ4C3g9QVfuT7AIOACeArVV1ckHdS1qwg29566hbAOCt3zs46ha6NO8QqKrvA79yhvp/Ae8+\nyzLbgG3zfU9J0uLyjmFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUsYX+bIQkvWx85o+/MeoWANj6\nV785tPdyT0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqY\nISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHVs6CGQZH2S\nQ0kOJ7l52O8vSTptqCGQ5ALgM8DvAKuB65OsHmYPkqTThr0nsA44XFXfr6qfATuBDUPuQZLUpKqG\n92bJ7wPrq+qP2usPAO+oqg9Pm28LsKW9/CXg0NCaPLPLgB+MuIfzhdviNLfFaW6L086XbfHGqhqb\naaYLh9HJXFXVdmD7qPs4Jcl4Va0ddR/nA7fFaW6L09wWp73UtsWwDwdNACsGXi9vNUnSCAw7BB4G\nViW5PMmrgI3A7iH3IElqhno4qKpOJPkw8DXgAuCuqto/zB7m6bw5NHUecFuc5rY4zW1x2ktqWwz1\nxLAk6fziHcOS1DFDQJI6ZghIUscMAUnq2Hl5s9j5Jsk9VbVp1H2MQpK3AMuA71TVjwfq66vqq6Pr\nbPjattjA1PaAqXtcdlfVwdF1NRpJ1gFVVQ+33/9aD3yvqu4bcWuaI68OmibJ9PsWArwL+AZAVf3e\n0JsakSR/AmwFDgJrgJuq6t427dGq+tVR9jdMSf4MuJ6p37s60srLmbrXZWdV3Taq3oYtySeY+hHI\nC4EHgHcA3wR+C/haVW0bYXvnjSR/WFV/O+o+ZmIITJPkUeAA8DdAMRUCX2Dqf3aq6l9G191wJdkH\n/FpV/TjJSuCLwN9V1V8m+beqevtIGxyiJP8OXFFV/zut/ipgf1WtGk1nw9f+u1gDXAQ8AyyvquNJ\nLmZqj/GXR9rgeSLJf1bVG0bdx0w8HPRCa4GbgD8H/rSq9ib5aU//+A94xalDQFX1ZJJrgC8meSNT\n4diT54HXA09Nqy9t03pyoqpOAj9J8h9VdRygqn6apKttkeS7Z5sELBlmL/NlCExTVc8Dn07yD+35\nGP1up2NJ1lTVXoC2R/C7wF3A20bb2tB9FNiT5HHg6VZ7A/CLwIfPutTL08+S/FxV/QS46lQxyWvp\nLxCXANcC/z2tHuBfh9/O3PX6j9uMquoI8AdJ3gscH3U/I7IJODFYqKoTwKYkfz2alkajqr6a5M1M\n/U2MwRPDD7dvxT35jap6Dv7/S9MprwQ2j6alkflH4NWnvigNSvLPw29n7jwnIEkd8z4BSeqYISBJ\nHTMEJKljhoAkdez/AGhX6eqOqoXlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11913bb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.category.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_data[\"title\"], train_data[\"category\"], test_size = 0.2)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_valid)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label_train, feature_vector_valid, label_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label_train)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, label_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# le_hostname = preprocessing.LabelEncoder()\n",
    "# le_hostname.fit_transform(train_data['hostname']).shape\n",
    "\n",
    "# le_publisher = preprocessing.LabelEncoder()\n",
    "# le_publisher.fit_transform(train_data['publisher'].fillna('UNKNOWN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(x, tokens_only=False):\n",
    "    for record, tag in zip(x, list(range(len(x)))):\n",
    "        if tokens_only:\n",
    "            yield gensim.utils.simple_preprocess(record)\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(record), [tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.concatenate([X_train, X_valid])\n",
    "all_corpus = list(read_corpus(X_all))\n",
    "\n",
    "train_corpus = all_corpus[:len(X_train)]\n",
    "valid_corpus = all_corpus[len(X_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['china', 'telecom', 'corporation', 'ltd', 'press', 'release', 'annual', 'results'], tags=[0]),\n",
       " TaggedDocument(words=['general', 'motors', 'recall', 'being', 'probed', 'by', 'doj'], tags=[1])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PV-DBOW plain\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "        epochs=20, workers=cores)\n",
    "\n",
    "# PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "model_dmm = Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "        epochs=20, workers=cores, alpha=0.05, comment='alpha=0.05')\n",
    "\n",
    "# PV-DM w/ concatenation - big, slow, experimental mode\n",
    "# window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "model_dmc = Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=5, negative=5, hs=0, min_count=2, sample=0, \n",
    "        epochs=20, workers=cores)\n",
    "\n",
    "for model in [model_dbow, model_dmm, model_dmc]:\n",
    "    model.build_vocab(all_corpus)\n",
    "    \n",
    "model_dbow_dmm = ConcatenatedDoc2Vec([model_dbow, model_dmm])\n",
    "model_dbow_dmc = ConcatenatedDoc2Vec([model_dbow, model_dmc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_dbow = gensim.models.doc2vec.Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "#         epochs=20, workers=cores)\n",
    "# model_dbow.build_vocab(train_corpus)\n",
    "# model_dbow.train(train_corpus, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "# model_dbow.build_vocab(train_corpus)\n",
    "# for epoch in range(40):\n",
    "#     model_dbow.train(utils.shuffle([x for x in train_corpus]), total_examples=len(train_corpus), epochs=1)\n",
    "#     model_dbow.alpha -= 0.002\n",
    "#     model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_for_learning(model, sents, reinfer=False):\n",
    "    if reinfer:\n",
    "        targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    else:\n",
    "        targets, regressors = zip(*[(doc.tags[0], model.docvecs[doc.tags[0]]) for doc in sents])\n",
    "    \n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinfer=True\n",
    "\n",
    "for model in [model_dbow, model_dmm, model_dmc, model_dbow_dmm, model_dbow_dmc]:\n",
    "    _y_train, _X_train = vec_for_learning(model_dbow, train_corpus, reinfer=reinfer)\n",
    "    _y_valid, _X_valid = vec_for_learning(model_dbow, valid_corpus, reinfer=reinfer)\n",
    "    logreg = LogisticRegression()\n",
    "    accuracy = train_model(logreg, _X_train, _y_train, _X_valid, _y_valid)\n",
    "    print(\"LR: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=3500)\n",
    "count_vect.fit(train_data[\"title\"])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(X_train)\n",
    "xvalid_count =  count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, N-Gram Vectors:  0.6409618573797679\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(LogisticRegression(), xtrain_count, Y_train, xvalid_count, Y_test)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, N-Gram Vectors:  0.6492537313432836\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier on Count Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_count, Y_train, xvalid_count, Y_test)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, WordLevel TF-IDF:  0.6442786069651741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(max_depth=5, n_estimators=150), xtrain_count.tocsc(), Y_train, xvalid_count.tocsc(), Y_test)\n",
    "print(\"Xgb, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.43283582089552236\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(SVC(), xtrain_count, Y_train, xvalid_count, Y_test)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, N-Gram Vectors:  0.6650082918739635\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(RandomForestClassifier(n_estimators=180, criterion='entropy'), xtrain_count, Y_train, xvalid_count, Y_test)\n",
    "print(\"RF, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60026385 0.3630363  0.59622196 0.39954338 0.75608037]\n",
      "0.543029172262257\n",
      "0.639202950714999\n"
     ]
    }
   ],
   "source": [
    "print(fbeta_score(Y_test, Y_predict, average=None, beta=2))\n",
    "print(fbeta_score(Y_test, Y_predict, average='macro', beta=2))\n",
    "print(fbeta_score(Y_test, Y_predict, average='weighted', beta=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=3000)\n",
    "tfidf_vect_ngram.fit(train_data[\"title\"])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, N-Gram Vectors:  0.6417910447761194\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(LogisticRegression(), xtrain_tfidf_ngram, Y_train, xvalid_tfidf_ngram, Y_test)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, N-Gram Vectors:  0.6500829187396352\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(MultinomialNB(), xtrain_tfidf_ngram, Y_train, xvalid_tfidf_ngram, Y_test)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, WordLevel TF-IDF:  0.6517412935323383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140), xtrain_tfidf_ngram.tocsc(), Y_train, xvalid_tfidf_ngram.tocsc(), Y_test)\n",
    "print(\"Xgb, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.43283582089552236\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(SVC(), xtrain_tfidf_ngram, Y_train, xvalid_tfidf_ngram, Y_test)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, N-Gram Vectors:  0.6650082918739635\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(RandomForestClassifier(n_estimators=180, criterion='entropy'), xtrain_tfidf_ngram, Y_train, xvalid_tfidf_ngram, Y_test)\n",
    "print(\"RF, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create Submission Using Different Mothods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=3500, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=3500)\n",
    "tfidf_vect_ngram.fit(train_data[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "train_tfidf_ngram =  tfidf_vect_ngram.transform(train_data[\"title\"])\n",
    "test_tfidf_ngram =  tfidf_vect_ngram.transform(test_data[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB on training set  0.704330512692882\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier on Ngram Level TF IDF Vectors\n",
    "classifier =  MultinomialNB()\n",
    "accuracy = train_model(classifier, train_tfidf_ngram, train_data[\"category\"], train_tfidf_ngram, train_data[\"category\"])\n",
    "print(\"NB on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB on training set  0.7355234776837565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "classifier = xgboost.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140)\n",
    "accuracy = train_model(classifier, train_tfidf_ngram.tocsc(), train_data[\"category\"], train_tfidf_ngram.tocsc(), train_data[\"category\"])\n",
    "print(\"XGB on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF on training set  0.9928654388584702\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=180, criterion='entropy')\n",
    "accuracy = train_model(classifier, train_tfidf_ngram, train_data[\"category\"], train_tfidf_ngram, train_data[\"category\"])\n",
    "print(\"RF on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruizhi/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# test_data[\"category\"] = classifier.predict(test_tfidf_ngram.tocsc())\n",
    "test_data[\"category\"] = classifier.predict(test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out=pd.DataFrame(test_data,columns=['article_id','category'])\n",
    "out.to_csv('prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
