{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "\n",
    "from sklearn import metrics,preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, fbeta_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./input/train_v2.csv\")\n",
    "test_data = pd.read_csv(\"./input/test_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6027, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3826, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#v2: remove numbers and punctuations\n",
    "whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "train_data['text']=\"\"\n",
    "#train_data['title_clean']=\"\"\n",
    "for i in range(len(train_data['title'])):\n",
    "        filename='raw_train_new/'+str(i+1)+'.txt'\n",
    "        title=train_data['title'][i]\n",
    "        title = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", title)\n",
    "        title = ''.join(filter(whitelist.__contains__, title)).lower()\n",
    "        title = ' '.join(title.split())\n",
    "       # train_data['title_clean'][i]=title\n",
    "        #add space to title\n",
    "        title=title+\" \"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r',errors='ignore') as data_file:\n",
    "                data=data_file.read().replace('\\n', '')\n",
    "                data = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", data)\n",
    "                data = ''.join(filter(whitelist.__contains__, data)).lower()\n",
    "                data=' '.join(data.split())\n",
    "            train_data['text'][i]=title*10+data\n",
    "        else:\n",
    "            train_data['text'][i]=title*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#v2 remove numbers and punctuations\n",
    "whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "test_data['text']=\"\"\n",
    "#test_data['title_clean']=\"\"\n",
    "for i in range(len(test_data['title'])):\n",
    "        filename='raw_test_new/'+str(i+1)+'.txt'\n",
    "        title=test_data['title'][i]\n",
    "        title = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", title)\n",
    "        title = ''.join(filter(whitelist.__contains__, title)).lower()\n",
    "        title = ' '.join(title.split())\n",
    "        #test_data['title_clean'][i]=title\n",
    "        title=title+\" \"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r',errors='ignore') as data_file:\n",
    "                data=data_file.read().replace('\\n', '')\n",
    "                data = re.sub(r\"[,:.;@#\\?\\-\\%\\/!&$]+\\ *\", \" \", data)\n",
    "                data = ''.join(filter(whitelist.__contains__, data)).lower()\n",
    "                data=' '.join(data.split())\n",
    "            test_data['text'][i]=title*10 +data\n",
    "        else:\n",
    "            test_data['text'][i]=title*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def train_model(classifier, feature_vector_train, label_train, feature_vector_valid, label_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label_train)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return sklearn.metrics.accuracy_score(predictions, label_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use news title to train tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_text=pd.concat([train_data['title'],test_data['title']]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9853\n"
     ]
    }
   ],
   "source": [
    "print(len(total_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=3500, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=3500)\n",
    "tfidf_vect_ngram.fit(total_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use news news title *10 + news content to do tfidf transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_ngram =  tfidf_vect_ngram.transform(train_data[\"text\"])\n",
    "test_tfidf_ngram =  tfidf_vect_ngram.transform(test_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB on training set  0.8319230131076821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "classifier = xgboost.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140)\n",
    "accuracy = train_model(classifier, train_tfidf_ngram.tocsc(), train_data[\"category\"], train_tfidf_ngram.tocsc(), train_data[\"category\"])\n",
    "print(\"XGB on training set \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=classifier.predict_proba(test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3826, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10037063, 0.02017497, 0.338339  , 0.02973611, 0.5113793 ],\n",
       "       [0.08138281, 0.03217706, 0.22272417, 0.0276122 , 0.63610375],\n",
       "       [0.05535575, 0.10685922, 0.24474008, 0.04040945, 0.5526355 ],\n",
       "       [0.07628933, 0.05074055, 0.23462062, 0.04981647, 0.588533  ],\n",
       "       [0.00455279, 0.00581613, 0.02667828, 0.00276371, 0.96018904],\n",
       "       [0.08533074, 0.04119757, 0.17929082, 0.05783598, 0.6363449 ],\n",
       "       [0.2278105 , 0.00968871, 0.38149652, 0.01776791, 0.3632364 ],\n",
       "       [0.02956243, 0.02622815, 0.10435862, 0.01901004, 0.8208408 ],\n",
       "       [0.09902731, 0.05111004, 0.35687304, 0.07238013, 0.42060953],\n",
       "       [0.16721213, 0.08650713, 0.17862843, 0.06461759, 0.5030347 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.6\n",
    "mask = np.amax(prob, axis=1) > THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ...,  True, False,  True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " ysemi = np.argmax(prob,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[   0    1    2    3    4]\n",
      " [ 693  262  777  286 1808]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(ysemi, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7340301974448316\n"
     ]
    }
   ],
   "source": [
    "final_clf = SVC(kernel='linear')\n",
    "accuracy = train_model(final_clf,\n",
    "                                  sp.vstack((train_tfidf_ngram, test_tfidf_ngram[mask])),\n",
    "                                  np.concatenate((train_data[\"category\"], ysemi[mask])), \n",
    "                                  train_tfidf_ngram, train_data[\"category\"])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=final_clf.predict(test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"category\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=pd.DataFrame(test_data,columns=['article_id','category'])\n",
    "out.to_csv('prediction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
