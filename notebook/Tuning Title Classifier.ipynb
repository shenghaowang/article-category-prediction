{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (classification_report, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading article titles and their labels.\n",
      "Constructing TF-IDF matrix for articles.\n",
      "Dimension of TF-IDF matrix:  (6027, 3500)\n",
      "Start training classifier...\n",
      "Training accuracy:  0.6716417910447762\n",
      "Accuracy: 0.6716\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading article titles and their labels.\")\n",
    "articles_info_df = pd.read_csv('input/train_v2.csv', index_col='article_id')\n",
    "article_titles = articles_info_df['title'].tolist()\n",
    "article_classes = articles_info_df['category'].tolist()\n",
    "\n",
    "print(\"Constructing TF-IDF matrix for articles.\")\n",
    "x = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                    ngram_range=(1,3), max_features=3500).fit_transform(article_titles)\n",
    "# x = TfidfVectorizer.fit_transform(article_titles)\n",
    "y = np.array(article_classes)\n",
    "\n",
    "print(\"Dimension of TF-IDF matrix: \", x.shape)\n",
    "print(\"Start training classifier...\")\n",
    "\n",
    "# Split training and validation datasets\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .2, random_state=12, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .2, random_state=12)\n",
    "#model = MultinomialNB().fit(x[train], y[train])\n",
    "model1 = XGBClassifier(max_depth=5, learning_rate=0.1,\n",
    "                       n_estimators=140).fit(x_train, y_train)\n",
    "predicts = model1.predict(x_val)\n",
    "\n",
    "# print(\"Precision: %s\" %round(precision_score(y_val, predicts, average='macro'), 4))\n",
    "# print(\"Recall: %s\" %round(recall_score(y_val, predicts, average='macro'), 4))\n",
    "# print(\"F1 score: %s\" %round(f1_score(y_val, predicts, average='macro'), 4))\n",
    "print(\"Accuracy: %s\" %round(accuracy_score(y_val, predicts), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63761654 0.63969125 0.63409086 0.64134413 0.6384516  0.63450236\n",
      " 0.64030958 0.63969212 0.63512843 0.64300432 0.63886396 0.63928019]\n",
      "[{'max_depth': 3, 'min_child_weight': 1}, {'max_depth': 3, 'min_child_weight': 3}, {'max_depth': 3, 'min_child_weight': 5}, {'max_depth': 5, 'min_child_weight': 1}, {'max_depth': 5, 'min_child_weight': 3}, {'max_depth': 5, 'min_child_weight': 5}, {'max_depth': 7, 'min_child_weight': 1}, {'max_depth': 7, 'min_child_weight': 3}, {'max_depth': 7, 'min_child_weight': 5}, {'max_depth': 9, 'min_child_weight': 1}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 5}]\n",
      "{'max_depth': 9, 'min_child_weight': 1}\n",
      "0.6430043153392759\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "    'min_child_weight': range(1, 6, 2)\n",
    "}\n",
    "# y_train_bi = label_binarize(y, classes=[0, 1, 2, 3])\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective='multi:softprob',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test1, n_jobs=4, scoring='accuracy', iid=False, cv=5)\n",
    "gsearch1.fit(x_train, y_train)\n",
    "print(gsearch1.cv_results_['mean_test_score'])\n",
    "print(gsearch1.cv_results_['params'])\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64424571 0.64154989 0.64403887 0.63906884 0.6415501  0.64072237\n",
      " 0.64300432 0.63989743 0.63988969 0.64362866 0.64383376 0.63844858\n",
      " 0.64217229 0.64030808 0.64611314 0.64384171]\n",
      "[{'max_depth': 8, 'min_child_weight': 0.1}, {'max_depth': 8, 'min_child_weight': 0.5}, {'max_depth': 8, 'min_child_weight': 1}, {'max_depth': 8, 'min_child_weight': 2}, {'max_depth': 9, 'min_child_weight': 0.1}, {'max_depth': 9, 'min_child_weight': 0.5}, {'max_depth': 9, 'min_child_weight': 1}, {'max_depth': 9, 'min_child_weight': 2}, {'max_depth': 10, 'min_child_weight': 0.1}, {'max_depth': 10, 'min_child_weight': 0.5}, {'max_depth': 10, 'min_child_weight': 1}, {'max_depth': 10, 'min_child_weight': 2}, {'max_depth': 12, 'min_child_weight': 0.1}, {'max_depth': 12, 'min_child_weight': 0.5}, {'max_depth': 12, 'min_child_weight': 1}, {'max_depth': 12, 'min_child_weight': 2}]\n",
      "{'max_depth': 12, 'min_child_weight': 1}\n",
      "0.6461131418975062\n",
      "Elapsed time: %s seconds... 343.8405\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {\n",
    "    'max_depth': [8, 9, 10, 12],\n",
    "    'min_child_weight': [0.1, 0.5, 1, 2]\n",
    "}\n",
    "start_time = time.time()\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective='multi:softprob',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test2, n_jobs=4, scoring='accuracy', iid=False, cv=5)\n",
    "gsearch2.fit(x_train, y_train)\n",
    "print(gsearch2.cv_results_['mean_test_score'])\n",
    "print(gsearch2.cv_results_['params'])\n",
    "print(gsearch2.best_params_)\n",
    "print(gsearch2.best_score_)\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64134413 0.64134564 0.64196998 0.64176251 0.64155461]\n",
      "[{'gamma': 0.0}, {'gamma': 0.1}, {'gamma': 0.2}, {'gamma': 0.3}, {'gamma': 0.4}]\n",
      "{'gamma': 0.2}\n",
      "0.6419699764009\n",
      "Elapsed time: %s seconds... 60.0255\n"
     ]
    }
   ],
   "source": [
    "param_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "start_time = time.time()\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective='multi:softprob',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test3, n_jobs=4, scoring='accuracy', iid=False, cv=5)\n",
    "gsearch3.fit(x_train, y_train)\n",
    "print(gsearch3.cv_results_['mean_test_score'])\n",
    "print(gsearch3.cv_results_['params'])\n",
    "print(gsearch3.best_params_)\n",
    "print(gsearch3.best_score_)\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune colsample_bytree and subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64010812 0.64176273 0.6400948  0.6425954  0.63989893 0.6394855\n",
      " 0.63906326 0.63781823 0.63947754 0.64093328 0.64134413 0.63989313\n",
      " 0.63906648 0.63907056 0.64176293 0.63968631]\n",
      "[{'colsample_bytree': 0.6, 'subsample': 0.6}, {'colsample_bytree': 0.6, 'subsample': 0.7}, {'colsample_bytree': 0.6, 'subsample': 0.8}, {'colsample_bytree': 0.6, 'subsample': 0.9}, {'colsample_bytree': 0.7, 'subsample': 0.6}, {'colsample_bytree': 0.7, 'subsample': 0.7}, {'colsample_bytree': 0.7, 'subsample': 0.8}, {'colsample_bytree': 0.7, 'subsample': 0.9}, {'colsample_bytree': 0.8, 'subsample': 0.6}, {'colsample_bytree': 0.8, 'subsample': 0.7}, {'colsample_bytree': 0.8, 'subsample': 0.8}, {'colsample_bytree': 0.8, 'subsample': 0.9}, {'colsample_bytree': 0.9, 'subsample': 0.6}, {'colsample_bytree': 0.9, 'subsample': 0.7}, {'colsample_bytree': 0.9, 'subsample': 0.8}, {'colsample_bytree': 0.9, 'subsample': 0.9}]\n",
      "{'colsample_bytree': 0.6, 'subsample': 0.9}\n",
      "0.6425953996668066\n"
     ]
    }
   ],
   "source": [
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6, 10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6, 10)]\n",
    "}\n",
    "start_time = time.time()\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective='multi:softprob',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test4, n_jobs=4, scoring='accuracy', iid=False, cv=5)\n",
    "gsearch4.fit(x_train, y_train)\n",
    "print(gsearch4.cv_results_['mean_test_score'])\n",
    "print(gsearch4.cv_results_['params'])\n",
    "print(gsearch4.best_params_)\n",
    "print(gsearch4.best_score_)\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64322211 0.64031366 0.63741101 0.63947754 0.64094403 0.63658373\n",
      " 0.63927566 0.63906648 0.64136155 0.63927695 0.63948292 0.63678753]\n",
      "[{'colsample_bytree': 0.8, 'subsample': 0.3}, {'colsample_bytree': 0.8, 'subsample': 0.4}, {'colsample_bytree': 0.8, 'subsample': 0.5}, {'colsample_bytree': 0.8, 'subsample': 0.6}, {'colsample_bytree': 0.9, 'subsample': 0.3}, {'colsample_bytree': 0.9, 'subsample': 0.4}, {'colsample_bytree': 0.9, 'subsample': 0.5}, {'colsample_bytree': 0.9, 'subsample': 0.6}, {'colsample_bytree': 1.0, 'subsample': 0.3}, {'colsample_bytree': 1.0, 'subsample': 0.4}, {'colsample_bytree': 1.0, 'subsample': 0.5}, {'colsample_bytree': 1.0, 'subsample': 0.6}]\n",
      "{'colsample_bytree': 0.8, 'subsample': 0.3}\n",
      "0.6432221057615536\n"
     ]
    }
   ],
   "source": [
    "param_test5 = {\n",
    "    'subsample':[i/10.0 for i in range(3, 7)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(8, 11)]\n",
    "}\n",
    "start_time = time.time()\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective='multi:softprob',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test5, n_jobs=4, scoring='accuracy', iid=False, cv=5)\n",
    "gsearch5.fit(x_train, y_train)\n",
    "print(gsearch5.cv_results_['mean_test_score'])\n",
    "print(gsearch5.cv_results_['params'])\n",
    "print(gsearch5.best_params_)\n",
    "print(gsearch5.best_score_)\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64134413 0.63989528 0.63989593 0.63844536 0.45239661]\n",
      "[{'reg_alpha': 1e-05}, {'reg_alpha': 0.01}, {'reg_alpha': 0.1}, {'reg_alpha': 1}, {'reg_alpha': 100}]\n",
      "{'reg_alpha': 1e-05}\n",
      "0.6413441267225569\n",
      "Elapsed time: %s seconds... 53.7113\n"
     ]
    }
   ],
   "source": [
    "param_test6 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "start_time = time.time()\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective='multi:softprob',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test6, n_jobs=4, scoring='accuracy', iid=False, cv=5)\n",
    "gsearch6.fit(x_train, y_train)\n",
    "print(gsearch6.cv_results_['mean_test_score'])\n",
    "print(gsearch6.cv_results_['params'])\n",
    "print(gsearch6.best_params_)\n",
    "print(gsearch6.best_score_)\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64134413 0.64197041 0.64010211 0.63989528 0.63927138]\n",
      "[{'reg_alpha': 0}, {'reg_alpha': 0.001}, {'reg_alpha': 0.005}, {'reg_alpha': 0.01}, {'reg_alpha': 0.05}]\n",
      "{'reg_alpha': 0.001}\n",
      "0.6419704077305247\n",
      "Elapsed time: %s seconds... 63.778\n"
     ]
    }
   ],
   "source": [
    "param_test7 = {\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "start_time = time.time()\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective='multi:softprob',\n",
    "                                                  nthread=4, scale_pos_weight=1, seed=27),\n",
    "                        param_grid = param_test7, n_jobs=4, scoring='accuracy', iid=False, cv=5)\n",
    "gsearch7.fit(x_train, y_train)\n",
    "print(gsearch7.cv_results_['mean_test_score'])\n",
    "print(gsearch7.cv_results_['params'])\n",
    "print(gsearch7.best_params_)\n",
    "print(gsearch7.best_score_)\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply classifier with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized parameters\n",
    "opt_max_depth = 9\n",
    "opt_min_child_weight = 1\n",
    "opt_gamma = 0.2\n",
    "opt_colsample_bytree = 0.6\n",
    "opt_subsample = 0.9\n",
    "opt_reg_alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7535\n",
      "Recall: 0.5396\n",
      "F1 score: 0.604\n",
      "Accuracy: 0.6542\n",
      "Elapsed time: %s seconds... 8.9601\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model2 = XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=opt_max_depth, \n",
    "                       min_child_weight=opt_min_child_weight, gamma=opt_gamma, subsample=opt_subsample,\n",
    "                       colsample_bytree=opt_colsample_bytree, reg_alpha=opt_reg_alpha,\n",
    "                       nthread=4, scale_pos_weight=1, seed=27).fit(x_train, y_train)\n",
    "predicts = model2.predict(x_val)\n",
    "print(\"Precision: %s\" %round(precision_score(y_val, predicts, average='macro'), 4))\n",
    "print(\"Recall: %s\" %round(recall_score(y_val, predicts, average='macro'), 4))\n",
    "print(\"F1 score: %s\" %round(f1_score(y_val, predicts, average='macro'), 4))\n",
    "print(\"Accuracy: %s\" %round(accuracy_score(y_val, predicts), 4))\n",
    "print(\"Elapsed time: %s seconds...\", round(time.time() - start_time, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White House plays down speedy role for US natu...</td>\n",
       "      <td>http://www.thestar.com.my/News/World/2014/03/0...</td>\n",
       "      <td>The Star Online</td>\n",
       "      <td>www.thestar.com.my</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian Stocks Broadly Higher After Selloff</td>\n",
       "      <td>http://www.nasdaq.com/article/asian-stocks-bro...</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>www.nasdaq.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herbalife Ltd. (HLF) Probe Earns Bill Ackman B...</td>\n",
       "      <td>http://www.valuewalk.com/2014/03/herbalife-ltd...</td>\n",
       "      <td>ValueWalk</td>\n",
       "      <td>www.valuewalk.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOE to Get Fourth Deputy Governor as Carney Fi...</td>\n",
       "      <td>http://www.businessweek.com/news/2014-03-11/bo...</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>www.businessweek.com</td>\n",
       "      <td>1.390000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pilots get scrutiny</td>\n",
       "      <td>http://www.dispatch.com/content/stories/nation...</td>\n",
       "      <td>Columbus Dispatch</td>\n",
       "      <td>www.dispatch.com</td>\n",
       "      <td>1.400000e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "article_id                                                      \n",
       "1           White House plays down speedy role for US natu...   \n",
       "2                   Asian Stocks Broadly Higher After Selloff   \n",
       "3           Herbalife Ltd. (HLF) Probe Earns Bill Ackman B...   \n",
       "4           BOE to Get Fourth Deputy Governor as Carney Fi...   \n",
       "5                                         Pilots get scrutiny   \n",
       "\n",
       "                                                          url  \\\n",
       "article_id                                                      \n",
       "1           http://www.thestar.com.my/News/World/2014/03/0...   \n",
       "2           http://www.nasdaq.com/article/asian-stocks-bro...   \n",
       "3           http://www.valuewalk.com/2014/03/herbalife-ltd...   \n",
       "4           http://www.businessweek.com/news/2014-03-11/bo...   \n",
       "5           http://www.dispatch.com/content/stories/nation...   \n",
       "\n",
       "                    publisher              hostname     timestamp  \n",
       "article_id                                                         \n",
       "1             The Star Online    www.thestar.com.my  1.390000e+12  \n",
       "2                      NASDAQ        www.nasdaq.com  1.390000e+12  \n",
       "3                   ValueWalk     www.valuewalk.com  1.390000e+12  \n",
       "4                Businessweek  www.businessweek.com  1.390000e+12  \n",
       "5           Columbus Dispatch      www.dispatch.com  1.400000e+12  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_articles_df = pd.read_csv('input/test_v2.csv', index_col='article_id')\n",
    "test_articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3),\n",
    "                         max_features=3500).fit_transform(test_articles_df['title'].tolist())\n",
    "test_predicts = model1.predict(x_test)\n",
    "test_predicts_df = pd.DataFrame(data=test_predicts, columns=['category'], index=test_articles_df.index)\n",
    "test_predicts_df.to_csv('title_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  61,  481,  168,   73, 3043])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(test_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set 0.742\n",
      "Accuracy on validation set 0.6716\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3), max_features=3500)\n",
    "tfidf_vect_ngram.fit(articles_info_df[\"title\"])\n",
    "train_tfidf_ngram = tfidf_vect_ngram.transform(articles_info_df[\"title\"])\n",
    "test_tfidf_ngram = tfidf_vect_ngram.transform(test_articles_df[\"title\"])\n",
    "# model3 = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140).fit(train_tfidf_ngram.to_csc(),\n",
    "#                                                                              articles_info_df['category'])\n",
    "model3 = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=140).fit(x_train, y_train)\n",
    "predicts = model3.predict(x_train)\n",
    "print(\"Accuracy on training set %s\" %round(accuracy_score(y_train, predicts), 4))\n",
    "predicts = model3.predict(x_val)\n",
    "print(\"Accuracy on validation set %s\" %round(accuracy_score(y_val, predicts), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles_df['category'] = model3.predict(test_tfidf_ngram)\n",
    "test_predicts_df = pd.DataFrame(test_articles_df, columns=['category'])\n",
    "test_predicts_df.to_csv('../predictions/title_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 645,  217,  738,  260, 1966])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(test_articles_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
